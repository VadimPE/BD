{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "Requests = pd.read_excel(\"Requests.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def google_search(text, Frame): #Парсинг поисковых запросов Google\n",
    "    frame = pd.DataFrame(columns=['Search Engine', 'Search Request', 'URL page'])\n",
    "    frame = Frame\n",
    "    url ='http://www.google.com/search?q='\n",
    "    page = requests.get(url + text) #Делаем запрос\n",
    "    soup = BeautifulSoup(page.text) #Создаем \" суп\" из страницы\n",
    "    h3 = soup.find_all(\"h3\",class_=\"r\") #Парсим ее\n",
    "    for elem in h3: #Вытаскиваем из нее ссылки\n",
    "        elem=elem.contents[0]\n",
    "        link=(\"https://www.google.com\" + elem[\"href\"])\n",
    "        line = {'Search Engine': 'Google' ,'IDRequest': i, 'URL page': link}\n",
    "        frame = frame.append(line, ignore_index=True)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sputnik_search(text, Frame): #Парсинг поисковых запросов Rambler\n",
    "    frame = pd.DataFrame(columns=['Search Engine', 'Search Request', 'URL page'])\n",
    "    frame = Frame\n",
    "    url ='http://www.sputnik.ru/search?q='\n",
    "    page = requests.get(url + text) #Делаем запрос\n",
    "    soup = BeautifulSoup(page.text) #Создаем \" суп\" из страницы\n",
    "    h3 = soup.find_all(\"div\", class_=\"b-result-title\") #Парсим ее\n",
    "    for elem in h3: #Вытаскиваем из нее ссылки\n",
    "        elem=elem.contents[0]\n",
    "        link=(elem[\"href\"])\n",
    "        line = {'Search Engine': 'Sputnik' ,'IDRequest': i, 'URL page': link}\n",
    "        frame = frame.append(line, ignore_index=True)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def webalta_search(text, Frame): #Парсинг поисковых запросов Rambler\n",
    "    frame = pd.DataFrame(columns=['Search Engine', 'Search Request', 'URL page'])\n",
    "    frame = Frame\n",
    "    url ='http://webalta.ru/srch?q='\n",
    "    page = requests.get(url + text) #Делаем запрос\n",
    "    soup = BeautifulSoup(page.text) #Создаем \" суп\" из страницы\n",
    "    h3 = soup.find_all(\"h1\", class_=\"\") #Парсим ее\n",
    "    for elem in h3: #Вытаскиваем из нее ссылки\n",
    "        elem=elem.contents[0]\n",
    "        link=(elem[\"href\"])\n",
    "        line = {'Search Engine': 'Webalta' ,'IDRequest': i, 'URL page': link}\n",
    "        frame = frame.append(line, ignore_index=True)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Frame = pd.DataFrame(columns=['Search Engine', 'IDRequest', 'URL page'])\n",
    "for i in range(Requests.shape[0]):\n",
    "    print i\n",
    "    text = Requests['Searches'][i]\n",
    "    Frame = google_search(text, Frame)\n",
    "    Frame = webalta_search(text, Frame)\n",
    "    Frame = sputnik_search(text, Frame)\n",
    "Frame.to_excel('url.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
